{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1564b36e",
   "metadata": {},
   "source": [
    "![banniere_one](img/banniere.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623668b9",
   "metadata": {},
   "source": [
    "# Classification Binaire de Pneumonie à partir de Radios Thoraciques\n",
    "\n",
    "La **pneumonie** est une infection des poumons causée par des bactéries, des virus ou des champignons. Elle entraîne une inflammation des sacs aériens (alvéoles), qui peuvent se remplir de liquide ou de pus, provoquant des symptômes comme la toux, de la fièvre et des difficultés respiratoires.\n",
    "\n",
    "Dans ce projet, nous entraînons un modèle de deep learning (MobileNetV3LArge) pour classifier automatiquement les radiographies thoraciques entre *normal* et *pneumonia*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847d5e47",
   "metadata": {},
   "source": [
    "Ce notebook présente un projet de classification binaire de pneumonie à partir de radios thoraciques. Nous allons suivre les étapes suivantes :\n",
    "\n",
    "1. Préparation et exploration du dataset\n",
    "2. Mise en place du modèle pré-entraîné et adaptation\n",
    "3. Entraînement du modèle\n",
    "4. Évaluation du modèle\n",
    "5. Suivi des expériences via MLflow\n",
    "6. Documentation et dépôt sur GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038b0354",
   "metadata": {},
   "source": [
    "## 1 . Préparation et exploration du dataset\n",
    "\n",
    "### Télécharger le dataset\n",
    "\n",
    "Nous allons utiliser le dataset Chest X-Ray Pneumonia. Assurez-vous que les images sont organisées dans des sous-dossiers `NORMAL` et `PNEUMONIA` dans le répertoire `data/train`, `data/test`, et `data/val`.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f808b1f0",
   "metadata": {},
   "source": [
    "### Préparation des dépendances python et des configurations nécessaires\n",
    "\n",
    "Ici nous allons rélaiser les différents import nécessaires pour le projet. il faudra avoir installé les dépendances avec le ```pip install -r  requirements.txt``` sinon rien ne fonctionnera. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec204ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des dépendances python nécessaire \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import random\n",
    "import subprocess\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, average_precision_score,\n",
    "                             log_loss, confusion_matrix, classification_report)\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV3Large\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "np.set_printoptions(linewidth=np.inf)\n",
    "np.set_printoptions(edgeitems=30) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3475373",
   "metadata": {},
   "source": [
    "Cette fonctionnalité permet de lancer mlflow ui sans avoir besoin de le lancer dans votre terminal il faut juste que vous soyez dans votre environnement python(virtuel ou non ) possédant votre mlflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0a872b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lancement et vérification MlFlow \n",
    "\n",
    "# Vérifier si le serveur MLflow est en cours d'exécution\n",
    "try:\n",
    "    response = requests.get(\"http://localhost:5000\")\n",
    "    response.raise_for_status()  # Cela lèvera une exception si le serveur n'est pas accessible\n",
    "    print(\"Le serveur MLflow UI est déjà en cours d'exécution.\")\n",
    "except requests.exceptions.RequestException:\n",
    "    print(\"Démarrage du serveur MLflow UI...\")\n",
    "    # Lancer le serveur MLflow UI dans un sous-processus\n",
    "    subprocess.Popen([\"mlflow\", \"ui\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    # Attendre un peu pour s'assurer que le serveur a le temps de démarrer\n",
    "    time.sleep(7)\n",
    "\n",
    "# Vérifier si une exécution est déjà en cours\n",
    "active_run = mlflow.active_run()\n",
    "if active_run is not None:\n",
    "    print(f\"Une exécution est déjà en cours : {active_run.info.run_id}. Fin de l'exécution.\")\n",
    "    mlflow.end_run()  # Terminer l'exécution active\n",
    "\n",
    "# Remplacez par l'ID de l'expérience que vous souhaitez supprimer\n",
    "\n",
    "\n",
    "# MLflow tracking\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"Pneumonia_Classification_MobileNet_V3_Large\")\n",
    "mlflow.start_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a05fa36",
   "metadata": {},
   "source": [
    "## Exploration des données \n",
    "\n",
    "Ici nous allons simplement affciher une radio pour vérifier qu'on arrive à la lire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12655d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge une image depuis un chemin local, l’image est chargé en 1 canal (valeur de pixel de 0 à 255)\n",
    "img = cv2.imread(\"data/train/NORMAL/IM-0115-0001.jpeg\", cv2.IMREAD_COLOR)\n",
    "\n",
    "# Observer l'image sous forme de matrice\n",
    "#print(img)\n",
    "\n",
    "# Visualisation de l'image\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Inspection des métadonnées de l'image\n",
    "print(f\"Shape (dimensions)    : {img.shape}\")\n",
    "print(f\"Type des valeurs      : {img.dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e664bf",
   "metadata": {},
   "source": [
    "dans l'exemple ci-dessus nous avons effectivement une image affichée donc nous pouvons continuer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d254ae18",
   "metadata": {},
   "source": [
    "### Prétraitement des images\n",
    "Ici nous allons trasnformer nos images pour qu'elles soit conformer à la taille recommandé voulue par notre modèle et en format couleur.\n",
    "nous allons ensuite les normaliser c'est à dire les convertir dans un format lisible pour notre modèle(ici: MobileNetV3Large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, img_read_type: int, target_size=(224, 224)):\n",
    "    \"\"\"\n",
    "    Charge les images et les étiquettes depuis un répertoire structuré en sous-dossiers 'NORMAL' et 'PNEUMONIA'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data_dir : str\n",
    "        Chemin du dossier contenant deux sous-dossiers : 'NORMAL' et 'PNEUMONIA', chacun contenant les images correspondantes.\n",
    "    img_read_type : int\n",
    "        Mode de lecture des images pour OpenCV (par exemple cv2.IMREAD_GRAYSCALE ou cv2.IMREAD_COLOR).\n",
    "    target_size : tuple (int, int), default=(224, 224)\n",
    "        Dimensions finales souhaitées pour les images après redimensionnement.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : \n",
    "        Tableau des images chargées et redimensionnées, converties en float32.\n",
    "        La forme dépend du mode de lecture (grayscale ou couleur).\n",
    "    \n",
    "    y : \n",
    "        Tableau des labels (0 pour 'NORMAL', 1 pour 'PNEUMONIA').\n",
    "    \"\"\"\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    label_map = {'NORMAL': 0, 'PNEUMONIA': 1}\n",
    "\n",
    "    for label_name in ['NORMAL', 'PNEUMONIA']:\n",
    "        class_dir = os.path.join(data_dir, label_name)\n",
    "        for filename in os.listdir(class_dir):\n",
    "            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                filepath = os.path.join(class_dir, filename)\n",
    "                img = cv2.imread(filepath, img_read_type)\n",
    "                if img is None:\n",
    "                    continue  # image illisible, on passe\n",
    "                img = cv2.resize(img, target_size)\n",
    "                X.append(img)\n",
    "                y.append(label_map[label_name])\n",
    "\n",
    "    X = np.array(X, dtype=np.float32)\n",
    "    y = np.array(y, dtype=np.float32)\n",
    "    return X, y\n",
    "\n",
    "X_train, y_train = load_data(\"data/train\", cv2.IMREAD_COLOR)\n",
    "X_test, y_test = load_data(\"data/test\", cv2.IMREAD_COLOR)\n",
    "X_valid, y_valid= load_data(\"data/val\", cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8d3957",
   "metadata": {},
   "source": [
    "Nos images sont maintenant maintenant conforme et nous allons les normaliser avec ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63f14ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créer un générateur d'images avec normalisation\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Créer des générateurs à partir des tableaux NumPy\n",
    "train_generator = datagen.flow(X_train, y_train, batch_size=32)\n",
    "valid_generator = datagen.flow(X_valid, y_valid, batch_size=32)\n",
    "test_generator = datagen.flow(X_test, y_test, batch_size=32,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da4a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(generator, num_batches=10):\n",
    "    \"\"\"\n",
    "    Calcule les poids de classe pour un ensemble d'étiquettes à partir d'un générateur.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    generator : ImageDataGenerator\n",
    "        Générateur d'images qui produit des lots d'images et d'étiquettes.\n",
    "    num_batches : int\n",
    "        Nombre de lots à utiliser pour le calcul des poids de classe.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionnaire des poids de classe.\n",
    "    \"\"\"\n",
    "    y = []\n",
    "    # Limiter le nombre de lots à itérer pour éviter une boucle infinie\n",
    "    for _ in range(num_batches):\n",
    "        try:\n",
    "            _, labels = next(generator)  # Obtenir le prochain lot\n",
    "            y.extend(labels)\n",
    "        except StopIteration:\n",
    "            break  # Sortir si le générateur est épuisé\n",
    "\n",
    "    y = np.array(y)\n",
    "\n",
    "    # Calculer les poids de classe\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "    \n",
    "    # Créer un dictionnaire de poids\n",
    "    class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "    \n",
    "    return class_weight_dict\n",
    "\n",
    "# Calculer les class_weights à partir du train_generator\n",
    "class_weights = compute_class_weights(train_generator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025ac08b",
   "metadata": {},
   "source": [
    "une fois les images préparé on vérfie que nous pouvons lire les images, on va prendre un échantillon de 10 images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331ca255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test images aléatoires\n",
    "\n",
    "# Obtenir un lot d'images et d'étiquettes depuis test_generator\n",
    "images, labels = next(iter(train_generator))\n",
    "\n",
    "# Mapping des classes\n",
    "label_name = {0: \"Normal\", 1: \"Pneumonia\"}\n",
    "\n",
    "# Choisir 10 indices aléatoires dans le batch\n",
    "num_images_to_display = 10\n",
    "indices = random.sample(range(len(images)), num_images_to_display)\n",
    "\n",
    "# Créer une figure pour afficher les images\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Affichage des images\n",
    "for i, idx in enumerate(indices):\n",
    "    plt.subplot(2, 5, i + 1)  # 2 lignes, 5 colonnes\n",
    "    plt.imshow((images[idx] / 255.0).astype(np.float32))  # /255 pour rendre l’image lisible\n",
    "    plt.title(label_name[labels[idx]])  # Afficher le nom de la classe\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()  # Ajuster l'espacement entre les sous-graphes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20376f0f",
   "metadata": {},
   "source": [
    "les images sont corects, on continue "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7e18e2",
   "metadata": {},
   "source": [
    "# Création modele "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5c5fb4",
   "metadata": {},
   "source": [
    "Nous allons créer notre modèle de données pour faire des predictions nous allons faire deux entrainement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc8b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = MobileNetV3Large(include_top=False, weights='imagenet', input_shape=(224, 224, 3))\n",
    "features = base_model.output\n",
    "features = GlobalAveragePooling2D()(features)\n",
    "features = Dropout(0.3)(features)\n",
    "output = Dense(1, activation='sigmoid')(features)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# Geler les couches du modèle de base\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ba3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler le modèle\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping pour éviter l'overfitting\n",
    "early_stop = EarlyStopping(patience=4, restore_best_weights=True)\n",
    "\n",
    "# Enregistrer les paramètres\n",
    "mlflow.log_param(\"model\", \"MobileNetV3Large\")\n",
    "mlflow.log_param(\"phase\", \"freeze\")\n",
    "mlflow.log_param(\"epochs\", 8)\n",
    "mlflow.log_param(\"batch_size\", 32)\n",
    "mlflow.log_param(\"optimizer\", \"adam\")\n",
    "mlflow.log_param(\"loss\", \"categorical_crossentropy\")\n",
    "mlflow.log_param(\"learning_rate\", 0.001) \n",
    "mlflow.log_param(\"trainable_layers\", sum([layer.trainable for layer in model.layers]))\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(X_train) // 32,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=len(X_valid) // 32,\n",
    "    epochs=8,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "# Évaluation modele avant fine_tuning \n",
    "loss, acc = model.evaluate(test_generator, steps=len(X_test) // 32)\n",
    "mlflow.log_metric(\"test_loss\", loss)\n",
    "mlflow.log_metric(\"test_accuracy\", acc)\n",
    "print(f\"Test accuracy: {acc*100:.2f}%\")\n",
    "print(f\"Pertes : {loss}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a33478e",
   "metadata": {},
   "source": [
    "On vérifie avec ce graphique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de20faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"MobileNetV3LargeFreeze - Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"graph/accuracy.png\")  # Sauvegarder la figure\n",
    "mlflow.log_artifact(\"graph/accuracy.png\")  # Enregistrer l'artefact dans MLflow\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654f320a",
   "metadata": {},
   "source": [
    "Ici nous allons \"degeler\" notre modele, ce principe permet à notre modele d'être plus performant et précis, nous allons dans ce cas-ci \"dégeler\" les 30 dernières couches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4092f30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Défreezer les 20 dernières couches du modèle \n",
    "for layer in base_model.layers[-20:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompiler avec un learning rate plus petit\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba9a400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nouveau early stopping\n",
    "early_stop_fine = EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "# Enregistrer les paramètres\n",
    "mlflow.log_param(\"phase_2\", \"unfreeze\")\n",
    "mlflow.log_param(\"unfreeze_epochs\", 8)\n",
    "mlflow.log_param(\"unfreeze_batch_size\", 32)\n",
    "mlflow.log_param(\"unfreeze_optimizer\", \"adam\")\n",
    "mlflow.log_param(\"unfreeze_loss\", \"categorical_crossentropy\")\n",
    "mlflow.log_param(\"unfreeze_learning_rate\", 0.00001)  # Si vous utilisez un learning rate spécifique\n",
    "mlflow.log_param(\"unfreeze_trainable_layers\", sum([layer.trainable for layer in model.layers]))\n",
    "\n",
    "history_finetune = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(X_train) // 32,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=len(X_valid) // 32,\n",
    "    epochs=8,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stop_fine]\n",
    ")\n",
    "\n",
    "# Évaluation\n",
    "fine_tuned_loss, fine_tuned_acc = model.evaluate(test_generator, steps=len(X_test) // 32)\n",
    "mlflow.log_metric(\"fine_tuned_accuracy\", fine_tuned_acc)\n",
    "mlflow.log_metric(\"fine_tuned_loss\", fine_tuned_loss)\n",
    "print(f\"Test accuracy: {fine_tuned_acc*100:.2f}%\")\n",
    "print(f\"Pertes : {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b779d0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test images aléatoires\n",
    "\n",
    "# Obtenir un lot d'images et d'étiquettes depuis test_generator\n",
    "images, labels = next(iter(test_generator))\n",
    "\n",
    "# Mapping des classes\n",
    "label_name = {0: \"Normal\", 1: \"Pneumonia\"}\n",
    "\n",
    "# Choisir 10 indices aléatoires dans le batch\n",
    "num_images_to_display = 10\n",
    "indices = random.sample(range(len(images)), num_images_to_display)\n",
    "\n",
    "# Créer une figure pour afficher les images\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Affichage des images\n",
    "for i, idx in enumerate(indices):\n",
    "    plt.subplot(2, 5, i + 1)  # 2 lignes, 5 colonnes\n",
    "    plt.imshow((images[idx] / 255.0).astype(np.float32))  # /255 pour rendre l’image lisible\n",
    "    plt.title(label_name[labels[idx]])  # Afficher le nom de la classe\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()  # Ajuster l'espacement entre les sous-graphes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c6ea88",
   "metadata": {},
   "source": [
    "Vérification avec le fine-tune nous observons que "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac0135f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_finetune.history['accuracy'], label='Train acc')\n",
    "plt.plot(history_finetune.history['val_accuracy'], label='Val acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"MobileNetV3LargeUnFreeze - Accuracy\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"graph/finetune_accuracy.png\")  # Sauvegarder la figure\n",
    "mlflow.log_artifact(\"graph/finetune_accuracy.png\")  # Enregistrer l'artefact dans MLflow\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0c47d8",
   "metadata": {},
   "source": [
    "# Graphique et Enregistrement MlFlow \n",
    "\n",
    "Ici nous allons faire des tests avec différents graphiques pour tester notre modele et vérifier sa précision, le paramétre le plus important ici est le recall, plus un recall est proche de 1 plus le modéle est précis, nous vérifions également d'autres graphiques \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5639be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédictions probabilistes (sorties sigmoid)\n",
    "y_true = test_generator.y\n",
    "y_probs = model.predict(test_generator, steps=len(test_generator))\n",
    "y_pred = (y_probs > 0.5).astype(\"int32\") \n",
    "\n",
    "accuracy_score_metric=accuracy_score(y_true, y_pred)\n",
    "precision_score_metric=precision_score(y_true, y_pred)\n",
    "recall_score_metric=recall_score(y_true, y_pred)\n",
    "f1_score_metric=f1_score(y_true, y_pred)\n",
    "roc_auc_score_metric=roc_auc_score(y_true, y_probs)\n",
    "average_precision_score_metric= average_precision_score(y_true, y_probs)\n",
    "log_loss_metric=log_loss(y_true, y_probs)\n",
    "\n",
    "# Calcul des métriques \n",
    "mlflow.log_metric(\"accuracy\", round(accuracy_score_metric,3))\n",
    "mlflow.log_metric(\"precision\", round(precision_score_metric,3))\n",
    "mlflow.log_metric(\"recall\", round(recall_score_metric,3))\n",
    "mlflow.log_metric(\"f1_score\", round(f1_score_metric,3))\n",
    "mlflow.log_metric(\"roc_auc\", round(roc_auc_score_metric,3))\n",
    "mlflow.log_metric(\"average_precision\", round(average_precision_score_metric,3))\n",
    "mlflow.log_metric(\"log_loss\", round(log_loss_metric,3))\n",
    "\n",
    "# Obtenir les classes réelles à partir du générateur\n",
    "y_test = np.concatenate([test_generator[i][1] for i in range(len(test_generator))])\n",
    "\n",
    "# Calculer la matrice de confusion\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Matrice de confusion :\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculer le rapport de classification\n",
    "class_report = classification_report(y_test, y_pred, target_names=['NORMAL', 'PNEUMONIA'])\n",
    "print(\"Rapport de classification :\")\n",
    "print(class_report)\n",
    "\n",
    "# Visualiser la matrice de confusion\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['NORMAL', 'PNEUMONIA'], yticklabels=['NORMAL', 'PNEUMONIA'])\n",
    "plt.ylabel('Vérité terrain')\n",
    "plt.xlabel('Prédictions')\n",
    "plt.title('Matrice de confusion')\n",
    "plt.savefig(\"graph/confuse_matrix.png\")\n",
    "mlflow.log_artifact(\"graph/confuse_matrix.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9345652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f\"ROC curve (AUC = {roc_auc:.2f})\")\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel(\"Taux de faux positifs\")\n",
    "plt.ylabel(\"Taux de vrais positifs\")\n",
    "plt.title(\"Courbe ROC\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.savefig(\"graph/roc_curve.png\")\n",
    "mlflow.log_artifact(\"graph/roc_curve.png\")\n",
    "\n",
    "# Precision-Recall curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_probs)\n",
    "avg_precision = average_precision_score(y_test, y_probs)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='blue', lw=2, label=f\"Average Precision = {avg_precision:.2f}\")\n",
    "plt.xlabel(\"Rappel\")\n",
    "plt.ylabel(\"Précision\")\n",
    "plt.title(\"Courbe Précision-Rappel\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True)\n",
    "plt.savefig(\"graph/precision_recall_curve.png\")\n",
    "mlflow.log_artifact(\"graph/precision_recall_curve.png\")\n",
    "\n",
    "# Rapport de classification\n",
    "#report = classification_report(y_test, y_pred, target_names=['Normal', 'Pneumonia'], output_dict=False)\n",
    "#print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20586a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir un lot d'images et d'étiquettes depuis test_generator\n",
    "images, labels = next(iter(test_generator))\n",
    "\n",
    "# Mapping des classes\n",
    "label_name = {0: \"Normal\", 1: \"Pneumonia\"}\n",
    "\n",
    "# Choisir un indice aléatoire dans le batch\n",
    "i = random.randint(0, len(images) - 1)\n",
    "\n",
    "# Prédiction\n",
    "proba = model.predict(np.expand_dims(images[i], axis=0))[0][0]\n",
    "predicted_class = int(proba > 0.5)\n",
    "\n",
    "# Affichage de l’image\n",
    "plt.imshow((images[i] / 255.0).astype(np.float32))  # /255 pour rendre l’image lisible\n",
    "plt.title(f\"Prédiction : {label_name[predicted_class]} ({proba:.2f})\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7149686",
   "metadata": {},
   "source": [
    "# Test Mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3679a1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère un mini-batch depuis le générateur\n",
    "X_batch, _ = train_generator[0]  # train_generator[0][0] = images, [0][1] = labels\n",
    "#example_input = X_batch[0:1]     # On prend une seule image, format (1, H, W, 3)\n",
    "example_input = np.random.rand(1, 224, 224, 3).astype(np.float32)\n",
    "# Inférer automatiquement la signature d'entrée/sortie\n",
    "signature = infer_signature(example_input, model.predict(example_input))\n",
    "\n",
    "mlflow.keras.log_model(\n",
    "    model,\n",
    "    artifact_path=\"model\",\n",
    "    signature=signature\n",
    ")\n",
    "\n",
    "# Terminer l'exécution\n",
    "mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
